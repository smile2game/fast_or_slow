{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c4e62a6",
   "metadata": {
    "papermill": {
     "duration": 0.008188,
     "end_time": "2025-03-26T14:57:59.063935",
     "exception": false,
     "start_time": "2025-03-26T14:57:59.055747",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Starter notebook: Fast or Slow with TensorFlow GNN\n",
    "\n",
    "This tutorial is designed to walk competitors of [predict-ai-model-runtime](https://kaggle.com/competitions/predict-ai-model-runtime) through the dataset and using [TensorFlow-GNN](https://github.com/tensorflow/gnn).\n",
    "\n",
    "In summary, you will:\n",
    "- `pip install` libraries\n",
    "- imports helper functions from another project, for reading data (`{layout, tile}_data`) and easier programming of GNN models (`implicit`).\n",
    "- read batches of graphs from the dataset, prints them on screen and explains them. \n",
    "- go through details for writing a GNN model and train it\n",
    "- produce an inference `csv` file on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6acb2b0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T14:57:59.080850Z",
     "iopub.status.busy": "2025-03-26T14:57:59.080483Z",
     "iopub.status.idle": "2025-03-26T14:58:25.753786Z",
     "shell.execute_reply": "2025-03-26T14:58:25.752649Z"
    },
    "papermill": {
     "duration": 26.684467,
     "end_time": "2025-03-26T14:58:25.756241",
     "exception": false,
     "start_time": "2025-03-26T14:57:59.071774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_gnn\r\n",
      "  Downloading tensorflow_gnn-1.0.3-py3-none-any.whl (836 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m836.8/836.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: apache-beam in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (2.46.0)\r\n",
      "Collecting google-vizier>=0.0.13 (from tensorflow_gnn)\r\n",
      "  Downloading google_vizier-0.1.24-py3-none-any.whl (801 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m801.4/801.4 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting ml-collections (from tensorflow_gnn)\r\n",
      "  Downloading ml_collections-1.0.0-py3-none-any.whl (76 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (3.1)\r\n",
      "Requirement already satisfied: pyarrow in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (9.0.0)\r\n",
      "Requirement already satisfied: tensorflow<3,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (2.12.0)\r\n",
      "Requirement already satisfied: attrs>=23.1.0 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (23.1.0)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.4.0)\r\n",
      "Requirement already satisfied: numpy>=1.21.5 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.23.5)\r\n",
      "Requirement already satisfied: protobuf>=3.6 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (3.20.3)\r\n",
      "Collecting portpicker>=1.3.1 (from google-vizier>=0.0.13->tensorflow_gnn)\r\n",
      "  Downloading portpicker-1.6.0-py3-none-any.whl (16 kB)\r\n",
      "Requirement already satisfied: grpcio>=1.49.0 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.51.3)\r\n",
      "Requirement already satisfied: googleapis-common-protos>=1.56.4 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.59.1)\r\n",
      "Requirement already satisfied: sqlalchemy>=1.4 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (2.0.17)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (23.5.26)\r\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (0.4.0)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (0.2.0)\r\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (3.9.0)\r\n",
      "Requirement already satisfied: jax>=0.3.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (0.4.13)\r\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (2.12.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (16.0.0)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (3.3.0)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (21.3)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (68.0.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (1.16.0)\r\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (2.12.3)\r\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (2.12.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (2.3.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (4.6.3)\r\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (1.14.1)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (0.32.0)\r\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (1.7)\r\n",
      "Requirement already satisfied: orjson<4.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (3.9.1)\r\n",
      "Collecting dill<0.3.2,>=0.3.1.1 (from apache-beam->tensorflow_gnn)\r\n",
      "  Downloading dill-0.3.1.1.tar.gz (151 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\r\n",
      "\u001b[?25hRequirement already satisfied: cloudpickle~=2.2.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (2.2.1)\r\n",
      "Requirement already satisfied: fastavro<2,>=0.23.6 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (1.7.4)\r\n",
      "Requirement already satisfied: fasteners<1.0,>=0.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (0.18)\r\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (2.7.0)\r\n",
      "Requirement already satisfied: httplib2<0.22.0,>=0.8 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (0.21.0)\r\n",
      "Requirement already satisfied: objsize<0.7.0,>=0.6.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (0.6.1)\r\n",
      "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (3.13.0)\r\n",
      "Requirement already satisfied: proto-plus<2,>=1.7.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (1.22.3)\r\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (1.4.2)\r\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2018.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (2023.3)\r\n",
      "Requirement already satisfied: regex>=2020.6.8 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (2023.6.3)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (2.31.0)\r\n",
      "Requirement already satisfied: zstandard<1,>=0.18.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (0.19.0)\r\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from ml-collections->tensorflow_gnn) (6.0)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<3,>=2.12.0->tensorflow_gnn) (0.40.0)\r\n",
      "Requirement already satisfied: docopt in /opt/conda/lib/python3.10/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->tensorflow_gnn) (0.6.2)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.10/site-packages (from httplib2<0.22.0,>=0.8->apache-beam->tensorflow_gnn) (3.0.9)\r\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow<3,>=2.12.0->tensorflow_gnn) (0.2.0)\r\n",
      "Requirement already satisfied: scipy>=1.7 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow<3,>=2.12.0->tensorflow_gnn) (1.11.2)\r\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from portpicker>=1.3.1->google-vizier>=0.0.13->tensorflow_gnn) (5.9.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->tensorflow_gnn) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->tensorflow_gnn) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->tensorflow_gnn) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->tensorflow_gnn) (2023.7.22)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.4->google-vizier>=0.0.13->tensorflow_gnn) (2.0.2)\r\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (2.20.0)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (1.0.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (3.4.3)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (0.7.1)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (2.3.7)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (4.2.4)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (0.2.7)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (4.9)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (1.3.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (2.1.3)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (0.4.8)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (3.2.2)\r\n",
      "Building wheels for collected packages: dill\r\n",
      "  Building wheel for dill (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78545 sha256=249a18d05e58a145d90204af9b8ae018337c8ff4f6c3d5335fd68d051c1ac8b2\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\r\n",
      "Successfully built dill\r\n",
      "Installing collected packages: portpicker, ml-collections, dill, google-vizier, tensorflow_gnn\r\n",
      "  Attempting uninstall: dill\r\n",
      "    Found existing installation: dill 0.3.7\r\n",
      "    Uninstalling dill-0.3.7:\r\n",
      "      Successfully uninstalled dill-0.3.7\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "multiprocess 0.70.15 requires dill>=0.3.7, but you have dill 0.3.1.1 which is incompatible.\r\n",
      "pathos 0.3.1 requires dill>=0.3.7, but you have dill 0.3.1.1 which is incompatible.\r\n",
      "pymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.23.5 which is incompatible.\r\n",
      "pymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed dill-0.3.1.1 google-vizier-0.1.24 ml-collections-1.0.0 portpicker-1.6.0 tensorflow_gnn-1.0.3\r\n",
      "Collecting tensorflow_ranking\r\n",
      "  Downloading tensorflow_ranking-0.5.5-py2.py3-none-any.whl (147 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: absl-py>=0.1.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow_ranking) (1.4.0)\r\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow_ranking) (1.23.5)\r\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow_ranking) (1.16.0)\r\n",
      "Requirement already satisfied: tensorflow-serving-api<3.0.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow_ranking) (2.12.1)\r\n",
      "Requirement already satisfied: tensorflow<2.16.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow_ranking) (2.12.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16.0->tensorflow_ranking) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16.0->tensorflow_ranking) (23.5.26)\r\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16.0->tensorflow_ranking) (0.4.0)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16.0->tensorflow_ranking) (0.2.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16.0->tensorflow_ranking) (1.51.3)\r\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16.0->tensorflow_ranking) (3.9.0)\r\n",
      "Requirement already satisfied: jax>=0.3.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16.0->tensorflow_ranking) (0.4.13)\r\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16.0->tensorflow_ranking) (2.12.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16.0->tensorflow_ranking) (16.0.0)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16.0->tensorflow_ranking) (3.3.0)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16.0->tensorflow_ranking) (21.3)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16.0->tensorflow_ranking) (3.20.3)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16.0->tensorflow_ranking) (68.0.0)\r\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16.0->tensorflow_ranking) (2.12.3)\r\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16.0->tensorflow_ranking) (2.12.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16.0->tensorflow_ranking) (2.3.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16.0->tensorflow_ranking) (4.6.3)\r\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16.0->tensorflow_ranking) (1.14.1)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16.0->tensorflow_ranking) (0.32.0)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.16.0->tensorflow_ranking) (0.40.0)\r\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow<2.16.0->tensorflow_ranking) (0.2.0)\r\n",
      "Requirement already satisfied: scipy>=1.7 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow<2.16.0->tensorflow_ranking) (1.11.2)\r\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<2.16.0->tensorflow_ranking) (2.20.0)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<2.16.0->tensorflow_ranking) (1.0.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<2.16.0->tensorflow_ranking) (3.4.3)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<2.16.0->tensorflow_ranking) (2.31.0)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<2.16.0->tensorflow_ranking) (0.7.1)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<2.16.0->tensorflow_ranking) (2.3.7)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow<2.16.0->tensorflow_ranking) (3.0.9)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.16.0->tensorflow_ranking) (4.2.4)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.16.0->tensorflow_ranking) (0.2.7)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.16.0->tensorflow_ranking) (4.9)\r\n",
      "Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.16.0->tensorflow_ranking) (1.26.15)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<2.16.0->tensorflow_ranking) (1.3.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<2.16.0->tensorflow_ranking) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<2.16.0->tensorflow_ranking) (3.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<2.16.0->tensorflow_ranking) (2023.7.22)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow<2.16.0->tensorflow_ranking) (2.1.3)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.16.0->tensorflow_ranking) (0.4.8)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<2.16.0->tensorflow_ranking) (3.2.2)\r\n",
      "Installing collected packages: tensorflow_ranking\r\n",
      "Successfully installed tensorflow_ranking-0.5.5\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_gnn --pre\n",
    "!pip install tensorflow_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6fc544a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T14:58:25.779711Z",
     "iopub.status.busy": "2025-03-26T14:58:25.778833Z",
     "iopub.status.idle": "2025-03-26T14:58:36.140657Z",
     "shell.execute_reply": "2025-03-26T14:58:36.139643Z"
    },
    "papermill": {
     "duration": 10.376224,
     "end_time": "2025-03-26T14:58:36.143133",
     "exception": false,
     "start_time": "2025-03-26T14:58:25.766909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install standard modules\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_gnn as tfgnn\n",
    "import tensorflow_ranking as tfr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d1e8b7",
   "metadata": {
    "papermill": {
     "duration": 0.010011,
     "end_time": "2025-03-26T14:58:36.163693",
     "exception": false,
     "start_time": "2025-03-26T14:58:36.153682",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The utility modules are based on the code on [github](): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bbf3504",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T14:58:36.186459Z",
     "iopub.status.busy": "2025-03-26T14:58:36.185366Z",
     "iopub.status.idle": "2025-03-26T14:59:07.116989Z",
     "shell.execute_reply": "2025-03-26T14:59:07.115790Z"
    },
    "papermill": {
     "duration": 30.946372,
     "end_time": "2025-03-26T14:59:07.120288",
     "exception": false,
     "start_time": "2025-03-26T14:58:36.173916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_gnn in /opt/conda/lib/python3.10/site-packages (1.0.3)\r\n",
      "Requirement already satisfied: apache-beam in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (2.46.0)\r\n",
      "Requirement already satisfied: google-vizier>=0.0.13 in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (0.1.24)\r\n",
      "Requirement already satisfied: ml-collections in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (1.0.0)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (3.1)\r\n",
      "Requirement already satisfied: pyarrow in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (9.0.0)\r\n",
      "Requirement already satisfied: tensorflow<3,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (2.12.0)\r\n",
      "Requirement already satisfied: attrs>=23.1.0 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (23.1.0)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.4.0)\r\n",
      "Requirement already satisfied: numpy>=1.21.5 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.23.5)\r\n",
      "Requirement already satisfied: protobuf>=3.6 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (3.20.3)\r\n",
      "Requirement already satisfied: portpicker>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.6.0)\r\n",
      "Requirement already satisfied: grpcio>=1.49.0 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.51.3)\r\n",
      "Requirement already satisfied: googleapis-common-protos>=1.56.4 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.59.1)\r\n",
      "Requirement already satisfied: sqlalchemy>=1.4 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (2.0.17)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (23.5.26)\r\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (0.4.0)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (0.2.0)\r\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (3.9.0)\r\n",
      "Requirement already satisfied: jax>=0.3.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (0.4.13)\r\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (2.12.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (16.0.0)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (3.3.0)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (21.3)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (68.0.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (1.16.0)\r\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (2.12.3)\r\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (2.12.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (2.3.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (4.6.3)\r\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (1.14.1)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (0.32.0)\r\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (1.7)\r\n",
      "Requirement already satisfied: orjson<4.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (3.9.1)\r\n",
      "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (0.3.1.1)\r\n",
      "Requirement already satisfied: cloudpickle~=2.2.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (2.2.1)\r\n",
      "Requirement already satisfied: fastavro<2,>=0.23.6 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (1.7.4)\r\n",
      "Requirement already satisfied: fasteners<1.0,>=0.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (0.18)\r\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (2.7.0)\r\n",
      "Requirement already satisfied: httplib2<0.22.0,>=0.8 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (0.21.0)\r\n",
      "Requirement already satisfied: objsize<0.7.0,>=0.6.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (0.6.1)\r\n",
      "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (3.13.0)\r\n",
      "Requirement already satisfied: proto-plus<2,>=1.7.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (1.22.3)\r\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (1.4.2)\r\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2018.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (2023.3)\r\n",
      "Requirement already satisfied: regex>=2020.6.8 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (2023.6.3)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (2.31.0)\r\n",
      "Requirement already satisfied: zstandard<1,>=0.18.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (0.19.0)\r\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from ml-collections->tensorflow_gnn) (6.0)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<3,>=2.12.0->tensorflow_gnn) (0.40.0)\r\n",
      "Requirement already satisfied: docopt in /opt/conda/lib/python3.10/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->tensorflow_gnn) (0.6.2)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.10/site-packages (from httplib2<0.22.0,>=0.8->apache-beam->tensorflow_gnn) (3.0.9)\r\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow<3,>=2.12.0->tensorflow_gnn) (0.2.0)\r\n",
      "Requirement already satisfied: scipy>=1.7 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow<3,>=2.12.0->tensorflow_gnn) (1.11.2)\r\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from portpicker>=1.3.1->google-vizier>=0.0.13->tensorflow_gnn) (5.9.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->tensorflow_gnn) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->tensorflow_gnn) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->tensorflow_gnn) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->tensorflow_gnn) (2023.7.22)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.4->google-vizier>=0.0.13->tensorflow_gnn) (2.0.2)\r\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (2.20.0)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (1.0.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (3.4.3)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (0.7.1)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (2.3.7)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (4.2.4)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (0.2.7)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (4.9)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (1.3.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (2.1.3)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (0.4.8)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (3.2.2)\r\n",
      "Requirement already satisfied: tensorflow_gnn in /opt/conda/lib/python3.10/site-packages (1.0.3)\r\n",
      "Requirement already satisfied: apache-beam in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (2.46.0)\r\n",
      "Requirement already satisfied: google-vizier>=0.0.13 in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (0.1.24)\r\n",
      "Requirement already satisfied: ml-collections in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (1.0.0)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (3.1)\r\n",
      "Requirement already satisfied: pyarrow in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (9.0.0)\r\n",
      "Requirement already satisfied: tensorflow<3,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (2.12.0)\r\n",
      "Requirement already satisfied: attrs>=23.1.0 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (23.1.0)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.4.0)\r\n",
      "Requirement already satisfied: numpy>=1.21.5 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.23.5)\r\n",
      "Requirement already satisfied: protobuf>=3.6 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (3.20.3)\r\n",
      "Requirement already satisfied: portpicker>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.6.0)\r\n",
      "Requirement already satisfied: grpcio>=1.49.0 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.51.3)\r\n",
      "Requirement already satisfied: googleapis-common-protos>=1.56.4 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.59.1)\r\n",
      "Requirement already satisfied: sqlalchemy>=1.4 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (2.0.17)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (23.5.26)\r\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (0.4.0)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (0.2.0)\r\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (3.9.0)\r\n",
      "Requirement already satisfied: jax>=0.3.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (0.4.13)\r\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (2.12.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (16.0.0)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (3.3.0)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (21.3)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (68.0.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (1.16.0)\r\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (2.12.3)\r\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (2.12.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (2.3.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (4.6.3)\r\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (1.14.1)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (0.32.0)\r\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (1.7)\r\n",
      "Requirement already satisfied: orjson<4.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (3.9.1)\r\n",
      "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (0.3.1.1)\r\n",
      "Requirement already satisfied: cloudpickle~=2.2.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (2.2.1)\r\n",
      "Requirement already satisfied: fastavro<2,>=0.23.6 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (1.7.4)\r\n",
      "Requirement already satisfied: fasteners<1.0,>=0.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (0.18)\r\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (2.7.0)\r\n",
      "Requirement already satisfied: httplib2<0.22.0,>=0.8 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (0.21.0)\r\n",
      "Requirement already satisfied: objsize<0.7.0,>=0.6.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (0.6.1)\r\n",
      "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (3.13.0)\r\n",
      "Requirement already satisfied: proto-plus<2,>=1.7.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (1.22.3)\r\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (1.4.2)\r\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2018.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (2023.3)\r\n",
      "Requirement already satisfied: regex>=2020.6.8 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (2023.6.3)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (2.31.0)\r\n",
      "Requirement already satisfied: zstandard<1,>=0.18.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (0.19.0)\r\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from ml-collections->tensorflow_gnn) (6.0)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<3,>=2.12.0->tensorflow_gnn) (0.40.0)\r\n",
      "Requirement already satisfied: docopt in /opt/conda/lib/python3.10/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->tensorflow_gnn) (0.6.2)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.10/site-packages (from httplib2<0.22.0,>=0.8->apache-beam->tensorflow_gnn) (3.0.9)\r\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow<3,>=2.12.0->tensorflow_gnn) (0.2.0)\r\n",
      "Requirement already satisfied: scipy>=1.7 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow<3,>=2.12.0->tensorflow_gnn) (1.11.2)\r\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from portpicker>=1.3.1->google-vizier>=0.0.13->tensorflow_gnn) (5.9.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->tensorflow_gnn) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->tensorflow_gnn) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->tensorflow_gnn) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->tensorflow_gnn) (2023.7.22)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.4->google-vizier>=0.0.13->tensorflow_gnn) (2.0.2)\r\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (2.20.0)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (1.0.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (3.4.3)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (0.7.1)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (2.3.7)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (4.2.4)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (0.2.7)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (4.9)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (1.3.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (2.1.3)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (0.4.8)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (3.2.2)\r\n",
      "Requirement already satisfied: tensorflow_gnn in /opt/conda/lib/python3.10/site-packages (1.0.3)\r\n",
      "Requirement already satisfied: apache-beam in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (2.46.0)\r\n",
      "Requirement already satisfied: google-vizier>=0.0.13 in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (0.1.24)\r\n",
      "Requirement already satisfied: ml-collections in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (1.0.0)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (3.1)\r\n",
      "Requirement already satisfied: pyarrow in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (9.0.0)\r\n",
      "Requirement already satisfied: tensorflow<3,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (2.12.0)\r\n",
      "Requirement already satisfied: attrs>=23.1.0 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (23.1.0)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.4.0)\r\n",
      "Requirement already satisfied: numpy>=1.21.5 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.23.5)\r\n",
      "Requirement already satisfied: protobuf>=3.6 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (3.20.3)\r\n",
      "Requirement already satisfied: portpicker>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.6.0)\r\n",
      "Requirement already satisfied: grpcio>=1.49.0 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.51.3)\r\n",
      "Requirement already satisfied: googleapis-common-protos>=1.56.4 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.59.1)\r\n",
      "Requirement already satisfied: sqlalchemy>=1.4 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (2.0.17)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (23.5.26)\r\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (0.4.0)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (0.2.0)\r\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (3.9.0)\r\n",
      "Requirement already satisfied: jax>=0.3.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (0.4.13)\r\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (2.12.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (16.0.0)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (3.3.0)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (21.3)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (68.0.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (1.16.0)\r\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (2.12.3)\r\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (2.12.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (2.3.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (4.6.3)\r\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (1.14.1)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow_gnn) (0.32.0)\r\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (1.7)\r\n",
      "Requirement already satisfied: orjson<4.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (3.9.1)\r\n",
      "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (0.3.1.1)\r\n",
      "Requirement already satisfied: cloudpickle~=2.2.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (2.2.1)\r\n",
      "Requirement already satisfied: fastavro<2,>=0.23.6 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (1.7.4)\r\n",
      "Requirement already satisfied: fasteners<1.0,>=0.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (0.18)\r\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (2.7.0)\r\n",
      "Requirement already satisfied: httplib2<0.22.0,>=0.8 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (0.21.0)\r\n",
      "Requirement already satisfied: objsize<0.7.0,>=0.6.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (0.6.1)\r\n",
      "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (3.13.0)\r\n",
      "Requirement already satisfied: proto-plus<2,>=1.7.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (1.22.3)\r\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (1.4.2)\r\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2018.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (2023.3)\r\n",
      "Requirement already satisfied: regex>=2020.6.8 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (2023.6.3)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (2.31.0)\r\n",
      "Requirement already satisfied: zstandard<1,>=0.18.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam->tensorflow_gnn) (0.19.0)\r\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from ml-collections->tensorflow_gnn) (6.0)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<3,>=2.12.0->tensorflow_gnn) (0.40.0)\r\n",
      "Requirement already satisfied: docopt in /opt/conda/lib/python3.10/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->tensorflow_gnn) (0.6.2)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.10/site-packages (from httplib2<0.22.0,>=0.8->apache-beam->tensorflow_gnn) (3.0.9)\r\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow<3,>=2.12.0->tensorflow_gnn) (0.2.0)\r\n",
      "Requirement already satisfied: scipy>=1.7 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow<3,>=2.12.0->tensorflow_gnn) (1.11.2)\r\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from portpicker>=1.3.1->google-vizier>=0.0.13->tensorflow_gnn) (5.9.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->tensorflow_gnn) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->tensorflow_gnn) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->tensorflow_gnn) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->tensorflow_gnn) (2023.7.22)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.4->google-vizier>=0.0.13->tensorflow_gnn) (2.0.2)\r\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (2.20.0)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (1.0.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (3.4.3)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (0.7.1)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (2.3.7)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (4.2.4)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (0.2.7)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (4.9)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (1.3.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (2.1.3)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (0.4.8)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow_gnn) (3.2.2)\r\n"
     ]
    }
   ],
   "source": [
    "# Install utility modules.\n",
    "\n",
    "import tpugraphsv1_layout_data_py as layout_data\n",
    "import tpugraphsv1_tile_data_py as tile_data\n",
    "import tpugraphsv1_implicit_py as implicit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1152931",
   "metadata": {
    "papermill": {
     "duration": 0.012923,
     "end_time": "2025-03-26T14:59:07.147017",
     "exception": false,
     "start_time": "2025-03-26T14:59:07.134094",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training Pipelines\n",
    "\n",
    "The following code is organized as:\n",
    "\n",
    " 1. Helper functions: MLP (`_mlp`) and Embedding layer (`_Opembedding`). The embedding layer amends a feature on the `op` nodes, with name `op_e`, by embedding the integral op IDs.\n",
    " 1. Pipeline code for training on the Layout collections.\n",
    " 1. Pipeline code for training on the Tile collection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c832f3c",
   "metadata": {
    "papermill": {
     "duration": 0.012355,
     "end_time": "2025-03-26T14:59:07.172324",
     "exception": false,
     "start_time": "2025-03-26T14:59:07.159969",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Helper functions, for both Layout and Tile collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47fed4e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T14:59:07.199734Z",
     "iopub.status.busy": "2025-03-26T14:59:07.199337Z",
     "iopub.status.idle": "2025-03-26T14:59:07.210097Z",
     "shell.execute_reply": "2025-03-26T14:59:07.209092Z"
    },
    "papermill": {
     "duration": 0.027018,
     "end_time": "2025-03-26T14:59:07.212219",
     "exception": false,
     "start_time": "2025-03-26T14:59:07.185201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def _mlp(dims, hidden_activation, l2reg=1e-4, use_bias=True):\n",
    "  \"\"\"Helper function for multi-layer perceptron (MLP).\"\"\"\n",
    "  layers = []\n",
    "  for i, dim in enumerate(dims):\n",
    "    if i > 0:\n",
    "      layers.append(tf.keras.layers.Activation(hidden_activation))\n",
    "    layers.append(tf.keras.layers.Dense(\n",
    "        dim, kernel_regularizer=tf.keras.regularizers.l2(l2reg),\n",
    "        use_bias=use_bias))\n",
    "  return tf.keras.Sequential(layers)\n",
    "\n",
    "\n",
    "class _OpEmbedding(tf.keras.Model):\n",
    "  \"\"\"Embeds GraphTensor.node_sets['op']['op'] nodes into feature 'op_e'.\"\"\"\n",
    "\n",
    "  def __init__(self, num_ops: int, embed_d: int, l2reg: float = 1e-4):\n",
    "    super().__init__()\n",
    "    self.embedding_layer = tf.keras.layers.Embedding(\n",
    "        num_ops, embed_d, activity_regularizer=tf.keras.regularizers.l2(l2reg))\n",
    "\n",
    "  def call(\n",
    "      self, graph: tfgnn.GraphTensor,\n",
    "      training: bool = False) -> tfgnn.GraphTensor:\n",
    "    op_features = dict(graph.node_sets['op'].features)\n",
    "    op_features['op_e'] = self.embedding_layer(\n",
    "        tf.cast(graph.node_sets['op']['op'], tf.int32))\n",
    "    return graph.replace_features(node_sets={'op': op_features})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40b4177",
   "metadata": {
    "papermill": {
     "duration": 0.013199,
     "end_time": "2025-03-26T14:59:07.238523",
     "exception": false,
     "start_time": "2025-03-26T14:59:07.225324",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Layout Training Pipeline\n",
    "\n",
    "We start by defining constants:\n",
    "\n",
    "1. Batch sizes = num graphs, num sampled nodes per graph, and num configurations per graph.\n",
    "1. Collection to train on: source (`xla` versus `nlp`) and search stragey (`random` versus `default`).\n",
    "\n",
    "Then, boilerplate code to prepare the datasets.\n",
    "\n",
    "Then, we dive deeper into the dataset examples (a batch of graphs from the tiles collection).\n",
    "\n",
    "Finally, details on defining a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dfa920",
   "metadata": {
    "papermill": {
     "duration": 0.013144,
     "end_time": "2025-03-26T14:59:07.264669",
     "exception": false,
     "start_time": "2025-03-26T14:59:07.251525",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define constants and choose subcollection\n",
    "\n",
    "We load `BATCH_SIZE` graphs per batch. Each will have "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ea99bf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T14:59:07.291947Z",
     "iopub.status.busy": "2025-03-26T14:59:07.291532Z",
     "iopub.status.idle": "2025-03-26T14:59:07.296725Z",
     "shell.execute_reply": "2025-03-26T14:59:07.295753Z"
    },
    "papermill": {
     "duration": 0.021255,
     "end_time": "2025-03-26T14:59:07.298749",
     "exception": false,
     "start_time": "2025-03-26T14:59:07.277494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LAYOUT_DATA_ROOT = '/kaggle/input/predict-ai-model-runtime/npz_all/npz/layout'\n",
    "SOURCE = 'xla'  # Can be \"xla\" or \"nlp\"\n",
    "SEARCH = 'random'  # Can be \"random\" or \"default\"\n",
    "\n",
    "# Batch size information.\n",
    "BATCH_SIZE = 16  # Number of graphs per batch.\n",
    "CONFIGS_PER_GRAPH = 5  # Number of configurations (features and target values) per graph.\n",
    "MAX_KEEP_NODES = 1000  # Useful for dropout.\n",
    "# `MAX_KEEP_NODES` is (or, is not) useful for Segment Dropout, if model uses\n",
    "# edges \"sampled_config\" and \"sampled_feed\" (or, \"config\" and \"feed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da6f904",
   "metadata": {
    "papermill": {
     "duration": 0.012636,
     "end_time": "2025-03-26T14:59:07.324121",
     "exception": false,
     "start_time": "2025-03-26T14:59:07.311485",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prepare `tf.data.Dataset` instances\n",
    "Specifically, `layout_train_ds` and `layout_valid_ds`.\n",
    "\n",
    "It can take ~10 minutes if you are running for the first time, for the caches to be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e057f02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T14:59:07.408733Z",
     "iopub.status.busy": "2025-03-26T14:59:07.407980Z",
     "iopub.status.idle": "2025-03-26T15:01:02.326907Z",
     "shell.execute_reply": "2025-03-26T15:01:02.325881Z"
    },
    "papermill": {
     "duration": 114.935645,
     "end_time": "2025-03-26T15:01:02.329497",
     "exception": false,
     "start_time": "2025-03-26T14:59:07.393852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset cache file:  cache/317e146d60640edb255d1dcb2d3235c8-cache.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [01:00<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving ...\n",
      "wrote cache/317e146d60640edb255d1dcb2d3235c8-cache.npz\n",
      "wrote cache/317e146d60640edb255d1dcb2d3235c8-cache.npz.graphs.txt\n",
      "dataset cache file:  cache/ed1b35ba5a151cd92dc0e4d41f4160ce-cache.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:07<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving ...\n",
      "wrote cache/ed1b35ba5a151cd92dc0e4d41f4160ce-cache.npz\n",
      "wrote cache/ed1b35ba5a151cd92dc0e4d41f4160ce-cache.npz.graphs.txt\n",
      "dataset cache file:  cache/437403654dcd7a1b5d98d25edfb15ce6-cache.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  5.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving ...\n",
      "wrote cache/437403654dcd7a1b5d98d25edfb15ce6-cache.npz\n",
      "wrote cache/437403654dcd7a1b5d98d25edfb15ce6-cache.npz.graphs.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "layout_data_root_dir = os.path.join(\n",
    "      os.path.expanduser(LAYOUT_DATA_ROOT), SOURCE, SEARCH)\n",
    "\n",
    "layout_npz_dataset = layout_data.get_npz_dataset(\n",
    "    layout_data_root_dir,\n",
    "    min_train_configs=CONFIGS_PER_GRAPH,\n",
    "    max_train_configs=500,  # If any graph has more than this configurations, it will be filtered [speeds up loading + training]\n",
    "    cache_dir='cache'\n",
    ")\n",
    "\n",
    "def pair_layout_graph_with_label(graph: tfgnn.GraphTensor):\n",
    "    \"\"\"Extracts label from graph (`tfgnn.GraphTensor`) and returns a pair of `(graph, label)`\"\"\"\n",
    "    # Return runtimes divded over large number: only ranking is required. The\n",
    "    # runtimes are in the 100K range\n",
    "    label = tf.cast(graph.node_sets['g']['runtimes'], tf.float32) / 1e7\n",
    "    return graph, label\n",
    "\n",
    "layout_train_ds = (\n",
    "      layout_npz_dataset.train.get_graph_tensors_dataset(\n",
    "          CONFIGS_PER_GRAPH, max_nodes=MAX_KEEP_NODES)\n",
    "      .shuffle(100, reshuffle_each_iteration=True)\n",
    "      .batch(BATCH_SIZE, drop_remainder=False)\n",
    "      .map(tfgnn.GraphTensor.merge_batch_to_components)\n",
    "      .map(pair_layout_graph_with_label))\n",
    "\n",
    "layout_valid_ds = (\n",
    "      layout_npz_dataset.validation.get_graph_tensors_dataset(\n",
    "          CONFIGS_PER_GRAPH)\n",
    "      .batch(BATCH_SIZE, drop_remainder=False)\n",
    "      .map(tfgnn.GraphTensor.merge_batch_to_components)\n",
    "      .map(pair_layout_graph_with_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1201c0",
   "metadata": {
    "papermill": {
     "duration": 0.017725,
     "end_time": "2025-03-26T15:01:02.365857",
     "exception": false,
     "start_time": "2025-03-26T15:01:02.348132",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Familiarize yourself with data\n",
    "\n",
    "Lets obtain an example from the dataset `layout_train_ds`, i.e., an instance of `GraphTensor` which encodes a batch\n",
    "of graphs. Luckily, using TF-GNN, we can describe our model as-if we are operating on a single graph, and naturally the\n",
    "model extends to multiple graphs!\n",
    "\n",
    "Let's take one example (containing a batch) and print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5afd56cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T15:01:02.402976Z",
     "iopub.status.busy": "2025-03-26T15:01:02.402164Z",
     "iopub.status.idle": "2025-03-26T15:01:10.827696Z",
     "shell.execute_reply": "2025-03-26T15:01:10.822036Z"
    },
    "papermill": {
     "duration": 8.454905,
     "end_time": "2025-03-26T15:01:10.838372",
     "exception": false,
     "start_time": "2025-03-26T15:01:02.383467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph_batch = \n",
      "GraphTensor(\n",
      "  context=Context(features={}, sizes=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], shape=(), indices_dtype=tf.int32),\n",
      "  node_set_names=['op', 'nconfig', 'g'],\n",
      "  edge_set_names=['config', 'feed', 'g_op', 'g_config', 'sampled_config', 'sampled_feed'])\n",
      "\n",
      "\n",
      "\n",
      "config_runtimes=\n",
      "tf.Tensor(\n",
      "[[ 253.52144    316.43967     26.934538   242.915       25.646969 ]\n",
      " [1521.6781    1522.0701    1521.9486    1521.7411    1524.3986   ]\n",
      " [   2.5040119    2.236224     2.232272     3.287496     3.4131932]\n",
      " [ 170.16063    307.25967     45.95725    313.74316     46.36177  ]\n",
      " [  64.65636     72.4549      76.29008    106.00212    141.60982  ]\n",
      " [ 165.00519    243.96109     28.122746    28.140358   208.03348  ]\n",
      " [ 220.5728     230.91374    222.266      191.25298    294.82498  ]\n",
      " [  19.184908    23.432436    12.112343    12.226385    17.121675 ]\n",
      " [   5.361403     5.369776     5.375624     5.3572764    7.597693 ]\n",
      " [ 515.85175   1297.9347    1096.3369    1210.8364     256.4385   ]\n",
      " [  46.135345    46.13864     46.140656    46.135643    46.14307  ]\n",
      " [ 451.98325    440.683      450.6255     216.51923    207.69316  ]\n",
      " [  31.820972    88.45033     30.883484    31.631325    31.685564 ]\n",
      " [   4.639314     5.944023     4.617502     5.140126     6.6208963]\n",
      " [  61.612915   111.31749    118.7066     139.6854     145.5425   ]\n",
      " [  31.137793    31.161076    19.210703    19.212746    19.209627 ]], shape=(16, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "graph_batch, config_runtimes = next(iter(layout_train_ds.take(1)))\n",
    "\n",
    "print('graph_batch = ')\n",
    "print(graph_batch)\n",
    "print('\\n\\n')\n",
    "print('config_runtimes=')\n",
    "print(config_runtimes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81631261",
   "metadata": {
    "papermill": {
     "duration": 0.087737,
     "end_time": "2025-03-26T15:01:11.018700",
     "exception": false,
     "start_time": "2025-03-26T15:01:10.930963",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**< Crash-course on TF-GNN >**\n",
    "\n",
    "Each `GraphTensor` contains three fields:\n",
    "\n",
    "1. `node_sets`, can be thought of `dict` from node type (str) in the graph (batch) to feature tensors for that node type.\n",
    "1. `edge_sets`, can be thought of `dict` from edge type (str) in the graph (batch) to adjacency, as two integer vectors: source IDs and target IDs -- i.e., all edges are directed, unless explicitly undirected by the model. If edge set `e` connects from node-set `n1` to node-set `n2`, then if `graph.edge_sets[\"e1\"].adjacency.source = [0, 13, ...]` and `graph.edge_sets[\"e1\"].adjacency.target = [1, 14, ...]` (must be of equal length), then node `0` from node-set `n1` points to node `1` from node-set `n2`. The IDs are zero-based, and used to index into the feature tensors at `graph.node_sets[\"n1\"]` and `graph.node_sets[\"n2\"]`.\n",
    "1. `context`, contains information per graph in the batch. We do not use this, for the layout collection, as we have singleton nodeset per graph with name `\"g\"` (with features accessible as `graph.node_sets[\"g\"]`)\n",
    "\n",
    "**</ Crash-course on TF-GNN >**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357d5d59",
   "metadata": {
    "papermill": {
     "duration": 0.105013,
     "end_time": "2025-03-26T15:01:11.248432",
     "exception": false,
     "start_time": "2025-03-26T15:01:11.143419",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, lets print the node-sets and the edge-sets of the example `graph_batch`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb2112f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T15:01:11.293570Z",
     "iopub.status.busy": "2025-03-26T15:01:11.292724Z",
     "iopub.status.idle": "2025-03-26T15:01:11.304614Z",
     "shell.execute_reply": "2025-03-26T15:01:11.303431Z"
    },
    "papermill": {
     "duration": 0.037212,
     "end_time": "2025-03-26T15:01:11.307362",
     "exception": false,
     "start_time": "2025-03-26T15:01:11.270150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph_batch.context = Context(features={}, sizes=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], shape=(), indices_dtype=tf.int32)\n",
      "\n",
      "\n",
      " #####  NODE SET \"g\" #########\n",
      "** Has sizes:  tf.Tensor([1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], shape=(16,), dtype=int32)\n",
      "\n",
      " Feature \"graph_id\" has values\n",
      "tf.Tensor(\n",
      "[b'shapemask.4x4.fp32' b'inference_mlperf_ssd_1200_batch_128'\n",
      " b'bert_classifier.2x2.fp32.performance' b'xception_imagenet'\n",
      " b'mnasnet_a1_batch_128' b'resnet_v2_50_batch_16'\n",
      " b'resnet_v1_50_official_batch_128_f32' b'resnet50.4x4.bf16'\n",
      " b'transformer.4x4.fp32.performance' b'efficientnet_b7_eval_batch_1'\n",
      " b'openai_v0_rnn_optimized' b'resnet_v2_152_batch_64'\n",
      " b'inference_mlperf_ssd_1200_batch_1' b'bert_pretraining.8x16.fp16'\n",
      " b'mnasnet_b1_batch_128' b'resnet50.2x2.fp32'], shape=(16,), dtype=string)\n",
      "\n",
      " Feature \"runtimes\" has values\n",
      "tf.Tensor(\n",
      "[[ 2535214392  3164396808   269345378  2429150002   256469680]\n",
      " [15216780914 15220700215 15219485801 15217410807 15243986365]\n",
      " [   25040118    22362239    22322721    32874962    34131931]\n",
      " [ 1701606241  3072596738   459572468  3137431511   463617698]\n",
      " [  646563584   724549037   762900761  1060021211  1416098237]\n",
      " [ 1650051902  2439610850   281227440   281403580  2080334819]\n",
      " [ 2205727878  2309137360  2222660117  1912529777  2948249812]\n",
      " [  191849084   234324357   121123420   122263848   171216748]\n",
      " [   53614030    53697759    53756244    53572764    75976925]\n",
      " [ 5158517972 12979346878 10963368621 12108364699  2564385144]\n",
      " [  461353465   461386398   461406545   461356441   461430701]\n",
      " [ 4519832768  4406830000  4506254802  2165192098  2076931618]\n",
      " [  318209744   884503317   308834858   316313261   316855661]\n",
      " [   46393141    59440231    46175024    51401262    66208965]\n",
      " [  616129148  1113174872  1187066007  1396854055  1455425085]\n",
      " [  311377925   311610768   192107018   192127464   192096274]], shape=(16, 5), dtype=int64)\n",
      "\n",
      " Feature \"kept_node_ratio\" has values\n",
      "tf.Tensor(\n",
      "[0.05168493 0.04033885 0.048391   0.210615   0.11303267 0.03138319\n",
      " 0.17214666 0.10793934 0.03811847 0.02292789 0.78308535 0.06656903\n",
      " 0.03914814 0.04687134 0.12873326 0.18942982], shape=(16,), dtype=float32)\n",
      "\n",
      "\n",
      " #####  NODE SET \"nconfig\" #########\n",
      "** Has sizes:  tf.Tensor(\n",
      "[ 681 2002 1143  295  262  162  166  161 1777 1158   62  468 3143 1142\n",
      "  193  161], shape=(16,), dtype=int32)\n",
      "\n",
      " Feature \"feats\" has values\n",
      "tf.Tensor(\n",
      "[[[0.6666667  0.16666667 0.         ... 0.         0.8        0.6       ]\n",
      "  [0.16666667 0.6666667  0.         ... 0.         0.8        0.6       ]\n",
      "  [0.6666667  0.16666667 0.         ... 0.         0.8        0.6       ]\n",
      "  [0.16666667 0.6666667  0.         ... 0.         0.8        0.6       ]\n",
      "  [0.6666667  0.16666667 0.         ... 0.         0.8        0.6       ]]\n",
      "\n",
      " [[0.16666667 0.6666667  0.         ... 0.         0.6        0.8       ]\n",
      "  [0.16666667 0.6666667  0.         ... 0.         0.6        0.8       ]\n",
      "  [0.6666667  0.16666667 0.         ... 0.         0.6        0.8       ]\n",
      "  [0.16666667 0.6666667  0.         ... 0.         0.8        0.6       ]\n",
      "  [0.6666667  0.16666667 0.         ... 0.         0.6        0.8       ]]\n",
      "\n",
      " [[0.16666667 0.6666667  0.         ... 0.         0.6        0.8       ]\n",
      "  [0.16666667 0.6666667  0.         ... 0.         0.6        0.8       ]\n",
      "  [0.6666667  0.16666667 0.         ... 0.         0.6        0.8       ]\n",
      "  [0.16666667 0.6666667  0.         ... 0.         0.8        0.6       ]\n",
      "  [0.6666667  0.16666667 0.         ... 0.         0.6        0.8       ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.5        0.6666667  0.         ... 0.         0.2        0.8       ]\n",
      "  [0.5        0.6666667  0.         ... 0.         0.8        0.2       ]\n",
      "  [0.6666667  0.5        0.         ... 0.         0.2        0.8       ]\n",
      "  [0.6666667  0.5        0.         ... 0.         0.2        0.8       ]\n",
      "  [0.6666667  0.5        0.         ... 0.         0.2        0.8       ]]\n",
      "\n",
      " [[0.5        0.6666667  0.         ... 0.         0.2        0.8       ]\n",
      "  [0.5        0.6666667  0.         ... 0.         0.8        0.2       ]\n",
      "  [0.6666667  0.5        0.         ... 0.         0.2        0.8       ]\n",
      "  [0.6666667  0.5        0.         ... 0.         0.2        0.8       ]\n",
      "  [0.6666667  0.5        0.         ... 0.         0.2        0.8       ]]\n",
      "\n",
      " [[0.5        0.6666667  0.         ... 0.         0.2        0.8       ]\n",
      "  [0.5        0.6666667  0.         ... 0.         0.8        0.2       ]\n",
      "  [0.6666667  0.5        0.         ... 0.         0.2        0.8       ]\n",
      "  [0.6666667  0.5        0.         ... 0.         0.2        0.8       ]\n",
      "  [0.6666667  0.5        0.         ... 0.         0.2        0.8       ]]], shape=(12976, 5, 14), dtype=float32)\n",
      "\n",
      "\n",
      " #####  NODE SET \"op\" #########\n",
      "** Has sizes:  tf.Tensor(\n",
      "[19348 24790 20665  4748  8847  5162  5809  5605 26234 43615  1277 15022\n",
      " 25544 21335  7768  5279], shape=(16,), dtype=int32)\n",
      "\n",
      " Feature \"op\" has values\n",
      "tf.Tensor([ 63  63   2 ...   2   2 100], shape=(241048,), dtype=uint8)\n",
      "\n",
      " Feature \"feats\" has values\n",
      "tf.Tensor(\n",
      "[[0.  0.  0.  ... 0.  0.  0. ]\n",
      " [0.  0.  0.  ... 0.  0.  0. ]\n",
      " [1.  0.  0.  ... 0.  0.  0. ]\n",
      " ...\n",
      " [0.  0.  0.  ... 0.2 0.  0. ]\n",
      " [0.  0.  0.  ... 0.2 0.  0. ]\n",
      " [1.  0.  0.  ... 0.  0.  0. ]], shape=(241048, 112), dtype=float32)\n",
      "\n",
      " Feature \"selected\" has values\n",
      "tf.Tensor([False False False ... False False False], shape=(241048,), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "# The `graph_batch` contains node-sets and edge-sets.\n",
    "# There are no context features for layout collection\n",
    "print('graph_batch.context =', graph_batch.context)\n",
    "# Note: graph_batch.context.sizes must be equal to BATCH_SIZE.\n",
    "# Lets print-out all features for all nodesets.\n",
    "\n",
    "for node_set_name in sorted(graph_batch.node_sets.keys()):\n",
    "    print(f'\\n\\n #####  NODE SET \"{node_set_name}\" #########')\n",
    "    print('** Has sizes: ', graph_batch.node_sets[node_set_name].sizes)\n",
    "    for feature_name in graph_batch.node_sets[node_set_name].features.keys():\n",
    "        print(f'\\n Feature \"{feature_name}\" has values')\n",
    "        print(graph_batch.node_sets[node_set_name][feature_name])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10f7a65",
   "metadata": {
    "papermill": {
     "duration": 0.021028,
     "end_time": "2025-03-26T15:01:11.350838",
     "exception": false,
     "start_time": "2025-03-26T15:01:11.329810",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**The node set `'g'` corresponds to the \"graph-level\"**. Since `BATCH_SIZE==16`, each tensor in `'g'` should have a leading dimension of `16`. The `graph_id` feature contains model names. Since `CONFIGS_PER_GRAPH_PER_EPOCH=5`, then feature 'runtimes' must be of shape `(16, 5)` with `graph_batch.node_sets['g']['runtimes'][i, j]` indicating the runtime when compiling graph `i` with configuration features `j`. These specific feature values must be found in `nconfig` node-set, as explained next.\n",
    "\n",
    "**Lets look at nodes per graph**. For instance, node set `op` contains the operation nodes in the tensorflow graph (e.g., element-wise add, matrix multiply, etc). Op-codes are stored in `graph_batch.node_sets['op']['op']`. Since each graph has variable number of nodes, the array `graph_batch.node_sets['op'].sizes` gives the number of `op` nodes per (of the `16`) graphs.\n",
    "\n",
    "Some nodes are configurable. The (*virtual*) node-set `nconfig` contains features for configurable nodes. The features are in `graph_batch.node_sets['nconfig']['feats']`.\n",
    "\n",
    "\n",
    "The edge-set `'config'` (next) indicates the correspondence between `nconfig` features and `op` nodes. Specifically, each (*virtual*) `config` node has degree of 1 and each `op` node has degree of 0 or 1 (on edge-set `'config'`).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fa307a",
   "metadata": {
    "papermill": {
     "duration": 0.021268,
     "end_time": "2025-03-26T15:01:11.395038",
     "exception": false,
     "start_time": "2025-03-26T15:01:11.373770",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's print-out all the edge-sets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcaca1da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T15:01:11.439318Z",
     "iopub.status.busy": "2025-03-26T15:01:11.438918Z",
     "iopub.status.idle": "2025-03-26T15:01:11.446528Z",
     "shell.execute_reply": "2025-03-26T15:01:11.445568Z"
    },
    "papermill": {
     "duration": 0.032322,
     "end_time": "2025-03-26T15:01:11.448746",
     "exception": false,
     "start_time": "2025-03-26T15:01:11.416424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " config edge set:  EdgeSet(features={}, sizes=[ 681 2002 1143  295  262  162  166  161 1777 1158   62  468 3143 1142\n",
      "  193  161], adjacency=Adjacency(source=('nconfig', <tf.Tensor: shape=(12976,), dtype=tf.int32>), target=('op', <tf.Tensor: shape=(12976,), dtype=tf.int32>)))\n",
      "\n",
      " config source nodes:  tf.Tensor([    0     1     2 ... 12973 12974 12975], shape=(12976,), dtype=int32)\n",
      "\n",
      " config target nodes:  tf.Tensor([  4103   4137   4165 ... 240334 240353 240372], shape=(12976,), dtype=int32)\n",
      "\n",
      " g_op edge set:  EdgeSet(features={}, sizes=[19348 24790 20665  4748  8847  5162  5809  5605 26234 43615  1277 15022\n",
      " 25544 21335  7768  5279], adjacency=Adjacency(source=('g', <tf.Tensor: shape=(241048,), dtype=tf.int32>), target=('op', <tf.Tensor: shape=(241048,), dtype=tf.int32>)))\n",
      "\n",
      " g_config edge set:  EdgeSet(features={}, sizes=[ 681 2002 1143  295  262  162  166  161 1777 1158   62  468 3143 1142\n",
      "  193  161], adjacency=Adjacency(source=('g', <tf.Tensor: shape=(12976,), dtype=tf.int32>), target=('nconfig', <tf.Tensor: shape=(12976,), dtype=tf.int32>)))\n"
     ]
    }
   ],
   "source": [
    "print('\\n config edge set: ', graph_batch.edge_sets['config'])  \n",
    "print('\\n config source nodes: ', graph_batch.edge_sets['config'].adjacency.source)\n",
    "print('\\n config target nodes: ', graph_batch.edge_sets['config'].adjacency.target)\n",
    "print('\\n g_op edge set: ', graph_batch.edge_sets['g_op'])\n",
    "print('\\n g_config edge set: ', graph_batch.edge_sets['g_config'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36903229",
   "metadata": {
    "papermill": {
     "duration": 0.021149,
     "end_time": "2025-03-26T15:01:11.491268",
     "exception": false,
     "start_time": "2025-03-26T15:01:11.470119",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The edge-set `'config'` pairs each `\"nconfig\"` node with one `\"op\"` node. To list the correspondences, you print the `.adjacency.source` and `.adjacency.target`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09615b5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T15:01:11.535616Z",
     "iopub.status.busy": "2025-03-26T15:01:11.535240Z",
     "iopub.status.idle": "2025-03-26T15:01:11.542261Z",
     "shell.execute_reply": "2025-03-26T15:01:11.541279Z"
    },
    "papermill": {
     "duration": 0.031627,
     "end_time": "2025-03-26T15:01:11.544366",
     "exception": false,
     "start_time": "2025-03-26T15:01:11.512739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EdgeSet(features={}, sizes=[ 681 2002 1143  295  262  162  166  161 1777 1158   62  468 3143 1142\n",
      "  193  161], adjacency=Adjacency(source=('nconfig', <tf.Tensor: shape=(12976,), dtype=tf.int32>), target=('op', <tf.Tensor: shape=(12976,), dtype=tf.int32>)))\n",
      "tf.Tensor([    0     1     2 ... 12973 12974 12975], shape=(12976,), dtype=int32)\n",
      "tf.Tensor([  4103   4137   4165 ... 240334 240353 240372], shape=(12976,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(graph_batch.edge_sets['config'])   # Holds directed adjacency as list of pairs of indices: nconfig->op\n",
    "print(graph_batch.edge_sets['config'].adjacency.source)  # Print nconfig indices (should be a range())\n",
    "print(graph_batch.edge_sets['config'].adjacency.target)  # Print corresponding `op` indices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a3b1be",
   "metadata": {
    "papermill": {
     "duration": 0.020973,
     "end_time": "2025-03-26T15:01:11.586700",
     "exception": false,
     "start_time": "2025-03-26T15:01:11.565727",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Other than `config` edges, the remainder of the edge-sets are:\n",
    "```\n",
    "'feed', 'g_op', 'g_config', 'sampled_config', 'sampled_feed'\n",
    "```\n",
    "\n",
    "The first (`feed`) is the actual computation graph! `op` nodes feed into `op` nodes. **Note: The \"transpose\" of this adjacency (implicit) matrix indicates the direction of information flow (models are later in the tutorial).**. The second (`g_op`) and third (`g_config`), group by graph, respectively, `op` nodes and the (virtual) `nconfig` nodes. This edge-set can be helpful for global-pooling operations. \n",
    "\n",
    "*Segment-level Training*: Finally, to implement some version of **dropout**, `sampled_config` and `sampled_feed` edge-sets contain edges to randomly-sampled `op` nodes. To do full-graph (training or inference), you may use `config` and `feed`. To do training with segment dropout (e.g., a naive version of https://arxiv.org/abs/2308.13490, to appear @ NeurIPS'23), you may use `sampled_config` and `sampled_feed`. You may adjust the number of **keep** nodes by setting `MAX_KEEP_NODES`. An edge only survives in `sampled_feed` only if both of its endpoints survived (segment-level) dropout. In our naive implementation here, nodes with contiguous indices are kept. However, you are welcome to re-implement a better segmentation strategy.\n",
    "\n",
    "\n",
    "*NOTE: When using TF-GNN (models to follow), you dont have to worry about `sizes`: just write your model code as-if you are operating on a single graph, and the code naturally extends to a batch of graphs.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfd9d63",
   "metadata": {
    "papermill": {
     "duration": 0.021127,
     "end_time": "2025-03-26T15:01:11.629176",
     "exception": false,
     "start_time": "2025-03-26T15:01:11.608049",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Modeling\n",
    "\n",
    "Before we define the full model (`ResModel`), lets run some modeling functions. For example, let's embed the op-codes.\n",
    "\n",
    "We have `layout_npz_dataset.num_ops` unique number of op codes, which determines the embedding size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a55f243",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T15:01:11.673960Z",
     "iopub.status.busy": "2025-03-26T15:01:11.672984Z",
     "iopub.status.idle": "2025-03-26T15:01:11.769306Z",
     "shell.execute_reply": "2025-03-26T15:01:11.768217Z"
    },
    "papermill": {
     "duration": 0.121212,
     "end_time": "2025-03-26T15:01:11.771697",
     "exception": false,
     "start_time": "2025-03-26T15:01:11.650485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of ops in the dataset= 119\n",
      "\n",
      "\n",
      " Before embedding, node-set \"op\"=\n",
      " NodeSet(features={'op': <tf.Tensor: shape=(241048,), dtype=tf.uint8>, 'feats': <tf.Tensor: shape=(241048, 112), dtype=tf.float32>, 'selected': <tf.Tensor: shape=(241048,), dtype=tf.bool>}, sizes=[19348 24790 20665  4748  8847  5162  5809  5605 26234 43615  1277 15022\n",
      " 25544 21335  7768  5279])\n",
      "\n",
      "\n",
      " After embedding, node-set \"op\"=\n",
      " NodeSet(features={'op': <tf.Tensor: shape=(241048,), dtype=tf.uint8>, 'feats': <tf.Tensor: shape=(241048, 112), dtype=tf.float32>, 'selected': <tf.Tensor: shape=(241048,), dtype=tf.bool>, 'op_e': <tf.Tensor: shape=(241048, 16), dtype=tf.float32>}, sizes=[19348 24790 20665  4748  8847  5162  5809  5605 26234 43615  1277 15022\n",
      " 25544 21335  7768  5279])\n"
     ]
    }
   ],
   "source": [
    "num_ops = layout_npz_dataset.num_ops\n",
    "print('number of ops in the dataset=', num_ops)\n",
    "\n",
    "embedding_layer = _OpEmbedding(num_ops, 16)  # 16-dimensional embedding, for demonstration.\n",
    "graph_batch_embedded_ops = embedding_layer(graph_batch)\n",
    "\n",
    "print('\\n\\n Before embedding, node-set \"op\"=\\n', graph_batch.node_sets['op'])\n",
    "print('\\n\\n After embedding, node-set \"op\"=\\n', graph_batch_embedded_ops.node_sets['op'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0e8df0",
   "metadata": {
    "papermill": {
     "duration": 0.017372,
     "end_time": "2025-03-26T15:01:11.807001",
     "exception": false,
     "start_time": "2025-03-26T15:01:11.789629",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "*Note: after embedding, an additional feature `\"op_e\"` shows-up.*\n",
    "\n",
    "Now, lets concatenate the configuration features with the embedding features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8534c3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T15:01:11.845559Z",
     "iopub.status.busy": "2025-03-26T15:01:11.844441Z",
     "iopub.status.idle": "2025-03-26T15:01:11.851440Z",
     "shell.execute_reply": "2025-03-26T15:01:11.850352Z"
    },
    "papermill": {
     "duration": 0.028445,
     "end_time": "2025-03-26T15:01:11.853652",
     "exception": false,
     "start_time": "2025-03-26T15:01:11.825207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "op_e.shape == (241048, 16)\n",
      "config_features.shape == (12976, 5, 14)\n"
     ]
    }
   ],
   "source": [
    "op_e = graph_batch_embedded_ops.node_sets['op']['op_e']\n",
    "config_features = graph_batch_embedded_ops.node_sets['nconfig']['feats']\n",
    "\n",
    "print('op_e.shape ==', op_e.shape)\n",
    "print('config_features.shape ==', config_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49428ed5",
   "metadata": {
    "papermill": {
     "duration": 0.022034,
     "end_time": "2025-03-26T15:01:11.898420",
     "exception": false,
     "start_time": "2025-03-26T15:01:11.876386",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There are two differences in the shapes, yet, we concatenate them.\n",
    "\n",
    "1. `op_e` has more nodes: every node has an op-code, but not every node is configurable. We first to resize the leading dimension of `config_features` to equal the leading dimension of `op_e`, by filling zeros for nodes that are not configurable.\n",
    "1. `config_features` is cuboid. The middle dimension identifies the configuration: there are `CONFIGS_PER_GRAPH` of them.\n",
    "\n",
    "\n",
    "For the first, we can multiply by the (sparse) \"config\" adjacency matrix -- a binary matrix where every is a one-hot and most rows are zero. If adjacency entry at `[i, j]` is set, then `graph.node_sets[\"nconfig\"][\"feats\"][j]`  contain configuration features for node `i` of `graph.node_sets[\"op\"]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e173e3af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T15:01:11.944567Z",
     "iopub.status.busy": "2025-03-26T15:01:11.943450Z",
     "iopub.status.idle": "2025-03-26T15:01:11.969258Z",
     "shell.execute_reply": "2025-03-26T15:01:11.968122Z"
    },
    "papermill": {
     "duration": 0.051218,
     "end_time": "2025-03-26T15:01:11.971661",
     "exception": false,
     "start_time": "2025-03-26T15:01:11.920443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config_adj.shape = (<tf.Tensor: shape=(), dtype=int32, numpy=241048>, <tf.Tensor: shape=(), dtype=int32, numpy=12976>)\n",
      "resized_config_features.shape = (241048, 5, 14)\n"
     ]
    }
   ],
   "source": [
    "config_adj = implicit.AdjacencyMultiplier(graph_batch_embedded_ops, 'config')\n",
    "print('config_adj.shape =', config_adj.shape)\n",
    "resized_config_features = config_adj @ config_features\n",
    "print('resized_config_features.shape =', resized_config_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425d522e",
   "metadata": {
    "papermill": {
     "duration": 0.018046,
     "end_time": "2025-03-26T15:01:12.009219",
     "exception": false,
     "start_time": "2025-03-26T15:01:11.991173",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, we want to broadcast the `op_e` feature matrix to a cuboid, by replicating on a (new) inner dimension so that we can finally combine the config features with op-embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "818e88d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T15:01:12.048022Z",
     "iopub.status.busy": "2025-03-26T15:01:12.047091Z",
     "iopub.status.idle": "2025-03-26T15:01:12.200341Z",
     "shell.execute_reply": "2025-03-26T15:01:12.199305Z"
    },
    "papermill": {
     "duration": 0.174811,
     "end_time": "2025-03-26T15:01:12.202368",
     "exception": false,
     "start_time": "2025-03-26T15:01:12.027557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined_features.shape =  (241048, 5, 30)\n"
     ]
    }
   ],
   "source": [
    "broadcasted_op_e = tf.stack([op_e] * CONFIGS_PER_GRAPH, axis=1)\n",
    "\n",
    "combined_features = tf.concat([broadcasted_op_e, resized_config_features], axis=-1)\n",
    "\n",
    "print('combined_features.shape = ', combined_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db05b17e",
   "metadata": {
    "papermill": {
     "duration": 0.021006,
     "end_time": "2025-03-26T15:01:12.245475",
     "exception": false,
     "start_time": "2025-03-26T15:01:12.224469",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, we want to do graph convolution layer (i.e., message-passing followed by non-linearity) among the `feed` edges. Usually, this can be done by left-multiplying the feature tensor with **some form** of an adjacency matrix. The exact form will determine the pooling (e.g., sum VS average). Let us use the symmetrically-normalized adjacency matrix with self-connections added (by Kipf & Welling, ICLR'17).\n",
    "\n",
    "We can compute such a matrix $\\widehat{A}$ as:\n",
    "\n",
    "$$A_\\textrm{undirected.w.selfconnections} \\leftarrow A + A^\\top + I$$\n",
    "\n",
    "\n",
    "$$D \\leftarrow \\mathbf{1}^\\top A_\\textrm{undirected.w.selfconnections}$$\n",
    "\n",
    "\n",
    "$$\\widehat{A} \\leftarrow D^{-\\frac{1}{2}} (A_\\textrm{undirected.w.selfconnections}) D^{-\\frac{1}{2}} $$\n",
    "\n",
    "Which is acheivable by the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "746998ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T15:01:12.290458Z",
     "iopub.status.busy": "2025-03-26T15:01:12.290080Z",
     "iopub.status.idle": "2025-03-26T15:01:12.379268Z",
     "shell.execute_reply": "2025-03-26T15:01:12.378108Z"
    },
    "papermill": {
     "duration": 0.11491,
     "end_time": "2025-03-26T15:01:12.382241",
     "exception": false,
     "start_time": "2025-03-26T15:01:12.267331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "adj_op_op = implicit.AdjacencyMultiplier(graph_batch_embedded_ops, 'feed')  # op->op\n",
    "adj_config = implicit.AdjacencyMultiplier(graph_batch_embedded_ops, 'config')  # nconfig->op\n",
    "\n",
    "adj_op_op_hat = (adj_op_op + adj_op_op.transpose()).add_eye()\n",
    "adj_op_op_hat = adj_op_op_hat.normalize_symmetric()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3202c13d",
   "metadata": {
    "papermill": {
     "duration": 0.02086,
     "end_time": "2025-03-26T15:01:12.424694",
     "exception": false,
     "start_time": "2025-03-26T15:01:12.403834",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Finally, the message passing can written as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f16134c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T15:01:12.472372Z",
     "iopub.status.busy": "2025-03-26T15:01:12.471985Z",
     "iopub.status.idle": "2025-03-26T15:01:27.431678Z",
     "shell.execute_reply": "2025-03-26T15:01:27.429698Z"
    },
    "papermill": {
     "duration": 14.984899,
     "end_time": "2025-03-26T15:01:27.436972",
     "exception": false,
     "start_time": "2025-03-26T15:01:12.452073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_times_x.shape = (241048, 5, 30)\n"
     ]
    }
   ],
   "source": [
    "A_times_X = adj_op_op_hat @ combined_features\n",
    "print('A_times_x.shape =', A_times_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d99366b",
   "metadata": {
    "papermill": {
     "duration": 0.018559,
     "end_time": "2025-03-26T15:01:27.478734",
     "exception": false,
     "start_time": "2025-03-26T15:01:27.460175",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, we put together everything above to write a model class `ResModel` (next), which has a couple more concepts:\n",
    "\n",
    "1. Adjacency for `\"g_op\"` and `\"g_config\"`, which is used to pool information from all ops and from configurable ops, to the graph level.\n",
    "1. Residual connections.\n",
    "1. Segment dropout. a forward-pass is computed on the entire graph (but, with `tf.stop_gradient`). Then, another forward pass is computed using only sampled edge-sets (`edgeset_prefix` is set to `\"sampled_\"` by `forward()`).\n",
    "\n",
    "Without further ado, `ResModel`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "727409b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T15:01:27.519806Z",
     "iopub.status.busy": "2025-03-26T15:01:27.519385Z",
     "iopub.status.idle": "2025-03-26T15:01:27.537520Z",
     "shell.execute_reply": "2025-03-26T15:01:27.536200Z"
    },
    "papermill": {
     "duration": 0.04191,
     "end_time": "2025-03-26T15:01:27.539877",
     "exception": false,
     "start_time": "2025-03-26T15:01:27.497967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResModel(tf.keras.Model):\n",
    "    \"\"\"GNN with residual connections.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, num_configs: int, num_ops: int, op_embed_dim: int = 32,\n",
    "        num_gnns: int = 2, mlp_layers: int = 2,\n",
    "        hidden_activation: str = 'leaky_relu',\n",
    "        hidden_dim: int = 32, reduction: str = 'sum'):\n",
    "        super().__init__()\n",
    "        self._num_configs = num_configs\n",
    "        self._num_ops = num_ops\n",
    "        self._op_embedding = _OpEmbedding(num_ops, op_embed_dim)\n",
    "        self._prenet = _mlp([hidden_dim] * mlp_layers, hidden_activation)\n",
    "        self._gc_layers = []\n",
    "        for _ in range(num_gnns):\n",
    "            self._gc_layers.append(_mlp([hidden_dim] * mlp_layers, hidden_activation))\n",
    "        self._postnet = _mlp([hidden_dim, 1], hidden_activation, use_bias=False)\n",
    "\n",
    "    def call(self, graph: tfgnn.GraphTensor, training: bool = False):\n",
    "        del training\n",
    "        return self.forward(graph, self._num_configs)\n",
    "\n",
    "    def _node_level_forward(\n",
    "        self, node_features: tf.Tensor,\n",
    "        config_features: tf.Tensor,\n",
    "        graph: tfgnn.GraphTensor, num_configs: int,\n",
    "        edgeset_prefix='') -> tf.Tensor:\n",
    "        adj_op_op = implicit.AdjacencyMultiplier(\n",
    "            graph, edgeset_prefix+'feed')  # op->op\n",
    "        adj_config = implicit.AdjacencyMultiplier(\n",
    "            graph, edgeset_prefix+'config')  # nconfig->op\n",
    "\n",
    "        adj_op_op_hat = (adj_op_op + adj_op_op.transpose()).add_eye()\n",
    "        adj_op_op_hat = adj_op_op_hat.normalize_symmetric()\n",
    "\n",
    "        x = node_features\n",
    "\n",
    "        x = tf.stack([x] * num_configs, axis=1)\n",
    "        config_features = 100 * (adj_config @ config_features)\n",
    "        x = tf.concat([config_features, x], axis=-1)\n",
    "        x = self._prenet(x)\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "\n",
    "        for layer in self._gc_layers:\n",
    "            y = x\n",
    "            y = tf.concat([config_features, y], axis=-1)\n",
    "            y = tf.nn.leaky_relu(layer(adj_op_op_hat @ y))\n",
    "            x += y\n",
    "        return x\n",
    "\n",
    "    def forward(\n",
    "        self, graph: tfgnn.GraphTensor, num_configs: int,\n",
    "        backprop=True) -> tf.Tensor:\n",
    "        graph = self._op_embedding(graph)\n",
    "\n",
    "        config_features = graph.node_sets['nconfig']['feats']\n",
    "        node_features = tf.concat([\n",
    "            graph.node_sets['op']['feats'],\n",
    "            graph.node_sets['op']['op_e']\n",
    "        ], axis=-1)\n",
    "\n",
    "        x_full = self._node_level_forward(\n",
    "            node_features=tf.stop_gradient(node_features),\n",
    "            config_features=tf.stop_gradient(config_features),\n",
    "            graph=graph, num_configs=num_configs)\n",
    "\n",
    "        if backprop:\n",
    "            x_backprop = self._node_level_forward(\n",
    "                node_features=node_features,\n",
    "                config_features=config_features,\n",
    "                graph=graph, num_configs=num_configs, edgeset_prefix='sampled_')\n",
    "\n",
    "            is_selected = graph.node_sets['op']['selected']\n",
    "            # Need to expand twice as `is_selected` is a vector (num_nodes) but\n",
    "            # x_{backprop, full} are 3D tensors (num_nodes, num_configs, num_feats).\n",
    "            is_selected = tf.expand_dims(is_selected, axis=-1)\n",
    "            is_selected = tf.expand_dims(is_selected, axis=-1)\n",
    "            x = tf.where(is_selected, x_backprop, x_full)\n",
    "        else:\n",
    "            x = x_full\n",
    "\n",
    "        adj_config = implicit.AdjacencyMultiplier(graph, 'config')\n",
    "\n",
    "        # Features for configurable nodes.\n",
    "        config_feats = (adj_config.transpose() @ x)\n",
    "\n",
    "        # Global pooling\n",
    "        adj_pool_op_sum = implicit.AdjacencyMultiplier(graph, 'g_op').transpose()\n",
    "        adj_pool_op_mean = adj_pool_op_sum.normalize_right()\n",
    "        adj_pool_config_sum = implicit.AdjacencyMultiplier(\n",
    "            graph, 'g_config').transpose()\n",
    "        x = self._postnet(tf.concat([\n",
    "            # (A D^-1) @ Features\n",
    "            adj_pool_op_mean @ x,\n",
    "            # l2_normalize( A @ Features )\n",
    "            tf.nn.l2_normalize(adj_pool_op_sum @ x, axis=-1),\n",
    "            # l2_normalize( A @ Features )\n",
    "            tf.nn.l2_normalize(adj_pool_config_sum @ config_feats, axis=-1),\n",
    "        ], axis=-1))\n",
    "\n",
    "        x = tf.squeeze(x, -1)\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e8644c",
   "metadata": {
    "papermill": {
     "duration": 0.018014,
     "end_time": "2025-03-26T15:01:27.576093",
     "exception": false,
     "start_time": "2025-03-26T15:01:27.558079",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training loop\n",
    "\n",
    "Create a model, objective function, and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74b26d2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T15:01:27.613765Z",
     "iopub.status.busy": "2025-03-26T15:01:27.613356Z",
     "iopub.status.idle": "2025-03-26T15:01:27.700290Z",
     "shell.execute_reply": "2025-03-26T15:01:27.699177Z"
    },
    "papermill": {
     "duration": 0.108929,
     "end_time": "2025-03-26T15:01:27.702853",
     "exception": false,
     "start_time": "2025-03-26T15:01:27.593924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = ResModel(CONFIGS_PER_GRAPH, layout_npz_dataset.num_ops)\n",
    "\n",
    "loss = tfr.keras.losses.ListMLELoss()  # (temperature=10)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-3, clipnorm=0.5)\n",
    "\n",
    "model.compile(loss=loss, optimizer=opt, metrics=[\n",
    "    tfr.keras.metrics.OPAMetric(name='opa_metric'),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6815b8a3",
   "metadata": {
    "papermill": {
     "duration": 0.019524,
     "end_time": "2025-03-26T15:01:27.741082",
     "exception": false,
     "start_time": "2025-03-26T15:01:27.721558",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Train for a few epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07d9f411",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T15:01:27.781231Z",
     "iopub.status.busy": "2025-03-26T15:01:27.780197Z",
     "iopub.status.idle": "2025-03-26T15:06:22.877991Z",
     "shell.execute_reply": "2025-03-26T15:06:22.876800Z"
    },
    "papermill": {
     "duration": 295.120282,
     "end_time": "2025-03-26T15:06:22.880368",
     "exception": false,
     "start_time": "2025-03-26T15:01:27.760086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 290s 56s/step - loss: 4.9169 - opa_metric: 0.4159 - val_loss: 4.8064 - val_opa_metric: 0.5429\n",
      " * [@0] Validation (NEW BEST): 0.5428571701049805\n",
      "Restoring parameters corresponding to the best validation OPA.\n"
     ]
    }
   ],
   "source": [
    "early_stop = 5  # If validation OPA did not increase in this many epochs, terminate training.\n",
    "best_params = None  # Stores parameters corresponding to best validation OPA, to restore to them after training.\n",
    "best_val_opa = -1  # Tracks best validation OPA\n",
    "best_val_at_epoch = -1  # At which epoch.\n",
    "epochs = 1  # Total number of training epochs.\n",
    "\n",
    "for i in range(epochs):\n",
    "    history = model.fit(\n",
    "        layout_train_ds, epochs=1, verbose=1, validation_data=layout_valid_ds,\n",
    "        validation_freq=1)\n",
    "\n",
    "    train_loss = history.history['loss'][-1]\n",
    "    train_opa = history.history['opa_metric'][-1]\n",
    "    val_loss = history.history['val_loss'][-1]\n",
    "    val_opa = history.history['val_opa_metric'][-1]\n",
    "    if val_opa > best_val_opa:\n",
    "        best_val_opa = val_opa\n",
    "        best_val_at_epoch = i\n",
    "        best_params = {v.ref: v + 0 for v in model.trainable_variables}\n",
    "        print(' * [@%i] Validation (NEW BEST): %s' % (i, str(val_opa)))\n",
    "    elif early_stop > 0 and i - best_val_at_epoch >= early_stop:\n",
    "      print('[@%i] Best accuracy was attained at epoch %i. Stopping.' % (i, best_val_at_epoch))\n",
    "      break\n",
    "\n",
    "# Restore best parameters.\n",
    "print('Restoring parameters corresponding to the best validation OPA.')\n",
    "assert best_params is not None\n",
    "for v in model.trainable_variables:\n",
    "    v.assign(best_params[v.ref])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a2a5dd",
   "metadata": {
    "papermill": {
     "duration": 0.018378,
     "end_time": "2025-03-26T15:06:22.917924",
     "exception": false,
     "start_time": "2025-03-26T15:06:22.899546",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Make Submission CSV file for this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a401c3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T15:06:22.956408Z",
     "iopub.status.busy": "2025-03-26T15:06:22.955876Z",
     "iopub.status.idle": "2025-03-26T16:11:54.670020Z",
     "shell.execute_reply": "2025-03-26T16:11:54.666978Z"
    },
    "papermill": {
     "duration": 3931.736744,
     "end_time": "2025-03-26T16:11:54.672880",
     "exception": false,
     "start_time": "2025-03-26T15:06:22.936136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "   Running inference on test set ...\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference:   0%|          | 0/8 [00:00<?, ?it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▌         | 1/20 [00:00<00:11,  1.68it/s]\u001b[A\n",
      " 10%|█         | 2/20 [00:01<00:08,  2.06it/s]\u001b[A\n",
      " 15%|█▌        | 3/20 [00:01<00:07,  2.22it/s]\u001b[A\n",
      " 20%|██        | 4/20 [00:01<00:06,  2.30it/s]\u001b[A\n",
      " 25%|██▌       | 5/20 [00:02<00:06,  2.35it/s]\u001b[A\n",
      " 30%|███       | 6/20 [00:02<00:05,  2.37it/s]\u001b[A\n",
      " 35%|███▌      | 7/20 [00:03<00:05,  2.38it/s]\u001b[A\n",
      " 40%|████      | 8/20 [00:03<00:05,  2.39it/s]\u001b[A\n",
      " 45%|████▌     | 9/20 [00:03<00:04,  2.40it/s]\u001b[A\n",
      " 50%|█████     | 10/20 [00:04<00:04,  2.40it/s]\u001b[A\n",
      " 55%|█████▌    | 11/20 [00:04<00:03,  2.40it/s]\u001b[A\n",
      " 60%|██████    | 12/20 [00:05<00:03,  2.41it/s]\u001b[A\n",
      " 65%|██████▌   | 13/20 [00:05<00:02,  2.40it/s]\u001b[A\n",
      " 70%|███████   | 14/20 [00:05<00:02,  2.42it/s]\u001b[A\n",
      " 75%|███████▌  | 15/20 [00:06<00:02,  2.42it/s]\u001b[A\n",
      " 80%|████████  | 16/20 [00:06<00:01,  2.27it/s]\u001b[A\n",
      " 85%|████████▌ | 17/20 [00:07<00:01,  2.18it/s]\u001b[A\n",
      " 90%|█████████ | 18/20 [00:07<00:00,  2.11it/s]\u001b[A\n",
      " 95%|█████████▌| 19/20 [00:08<00:00,  2.03it/s]\u001b[A\n",
      "100%|██████████| 20/20 [00:08<00:00,  2.26it/s]\n",
      "Inference:  12%|█▎        | 1/8 [00:09<01:06,  9.44s/it]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▌         | 1/20 [00:43<13:37, 43.00s/it]\u001b[A\n",
      " 10%|█         | 2/20 [01:26<12:58, 43.26s/it]\u001b[A\n",
      " 15%|█▌        | 3/20 [02:10<12:18, 43.44s/it]\u001b[A\n",
      " 20%|██        | 4/20 [02:53<11:32, 43.26s/it]\u001b[A\n",
      " 25%|██▌       | 5/20 [03:36<10:50, 43.34s/it]\u001b[A\n",
      " 30%|███       | 6/20 [04:20<10:08, 43.44s/it]\u001b[A\n",
      " 35%|███▌      | 7/20 [05:19<10:32, 48.64s/it]\u001b[A\n",
      " 40%|████      | 8/20 [06:17<10:18, 51.58s/it]\u001b[A\n",
      " 45%|████▌     | 9/20 [07:01<09:02, 49.35s/it]\u001b[A\n",
      " 50%|█████     | 10/20 [07:44<07:54, 47.41s/it]\u001b[A\n",
      " 55%|█████▌    | 11/20 [08:28<06:55, 46.18s/it]\u001b[A\n",
      " 60%|██████    | 12/20 [09:12<06:03, 45.44s/it]\u001b[A\n",
      " 65%|██████▌   | 13/20 [09:55<05:12, 44.69s/it]\u001b[A\n",
      " 70%|███████   | 14/20 [10:38<04:25, 44.28s/it]\u001b[A\n",
      " 75%|███████▌  | 15/20 [11:22<03:40, 44.16s/it]\u001b[A\n",
      " 80%|████████  | 16/20 [12:05<02:55, 43.90s/it]\u001b[A\n",
      " 85%|████████▌ | 17/20 [12:49<02:11, 43.89s/it]\u001b[A\n",
      " 90%|█████████ | 18/20 [13:33<01:28, 44.04s/it]\u001b[A\n",
      " 95%|█████████▌| 19/20 [14:17<00:43, 43.83s/it]\u001b[A\n",
      "100%|██████████| 20/20 [15:04<00:00, 45.23s/it]\n",
      "Inference:  25%|██▌       | 2/8 [15:14<53:38, 536.38s/it]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▌         | 1/20 [00:23<07:29, 23.64s/it]\u001b[A\n",
      " 10%|█         | 2/20 [01:09<11:01, 36.75s/it]\u001b[A\n",
      " 15%|█▌        | 3/20 [01:33<08:47, 31.03s/it]\u001b[A\n",
      " 20%|██        | 4/20 [01:57<07:31, 28.21s/it]\u001b[A\n",
      " 25%|██▌       | 5/20 [02:21<06:38, 26.58s/it]\u001b[A\n",
      " 30%|███       | 6/20 [02:44<05:56, 25.48s/it]\u001b[A\n",
      " 35%|███▌      | 7/20 [03:08<05:23, 24.85s/it]\u001b[A\n",
      " 40%|████      | 8/20 [03:31<04:53, 24.45s/it]\u001b[A\n",
      " 45%|████▌     | 9/20 [03:55<04:26, 24.27s/it]\u001b[A\n",
      " 50%|█████     | 10/20 [04:18<03:59, 23.96s/it]\u001b[A\n",
      " 55%|█████▌    | 11/20 [04:42<03:35, 23.89s/it]\u001b[A\n",
      " 60%|██████    | 12/20 [05:06<03:10, 23.81s/it]\u001b[A\n",
      " 65%|██████▌   | 13/20 [05:30<02:46, 23.81s/it]\u001b[A\n",
      " 70%|███████   | 14/20 [05:53<02:21, 23.64s/it]\u001b[A\n",
      " 75%|███████▌  | 15/20 [06:17<01:58, 23.70s/it]\u001b[A\n",
      " 80%|████████  | 16/20 [06:40<01:34, 23.67s/it]\u001b[A\n",
      " 85%|████████▌ | 17/20 [07:04<01:10, 23.52s/it]\u001b[A\n",
      " 90%|█████████ | 18/20 [07:27<00:47, 23.52s/it]\u001b[A\n",
      " 95%|█████████▌| 19/20 [07:51<00:23, 23.57s/it]\u001b[A\n",
      "100%|██████████| 20/20 [08:14<00:00, 24.74s/it]\n",
      "Inference:  38%|███▊      | 3/8 [23:30<43:08, 517.76s/it]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▌         | 1/20 [00:24<07:42, 24.32s/it]\u001b[A\n",
      " 10%|█         | 2/20 [00:48<07:21, 24.51s/it]\u001b[A\n",
      " 15%|█▌        | 3/20 [01:13<06:58, 24.60s/it]\u001b[A\n",
      " 20%|██        | 4/20 [01:38<06:34, 24.64s/it]\u001b[A\n",
      " 25%|██▌       | 5/20 [02:02<06:08, 24.59s/it]\u001b[A\n",
      " 30%|███       | 6/20 [02:27<05:44, 24.58s/it]\u001b[A\n",
      " 35%|███▌      | 7/20 [03:10<06:38, 30.66s/it]\u001b[A\n",
      " 40%|████      | 8/20 [03:41<06:08, 30.73s/it]\u001b[A\n",
      " 45%|████▌     | 9/20 [04:07<05:20, 29.12s/it]\u001b[A\n",
      " 50%|█████     | 10/20 [04:32<04:38, 27.88s/it]\u001b[A\n",
      " 55%|█████▌    | 11/20 [04:57<04:02, 26.99s/it]\u001b[A\n",
      " 60%|██████    | 12/20 [05:22<03:30, 26.36s/it]\u001b[A\n",
      " 65%|██████▌   | 13/20 [05:46<03:00, 25.75s/it]\u001b[A\n",
      " 70%|███████   | 14/20 [06:10<02:32, 25.39s/it]\u001b[A\n",
      " 75%|███████▌  | 15/20 [06:35<02:06, 25.22s/it]\u001b[A\n",
      " 80%|████████  | 16/20 [07:00<01:40, 25.16s/it]\u001b[A\n",
      " 85%|████████▌ | 17/20 [07:25<01:14, 24.95s/it]\u001b[A\n",
      " 90%|█████████ | 18/20 [07:50<00:49, 24.95s/it]\u001b[A\n",
      " 95%|█████████▌| 19/20 [08:15<00:24, 24.94s/it]\u001b[A\n",
      "100%|██████████| 20/20 [08:40<00:00, 26.01s/it]\n",
      "Inference:  50%|█████     | 4/8 [32:11<34:35, 518.98s/it]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▍         | 1/21 [00:04<01:36,  4.80s/it]\u001b[A\n",
      " 10%|▉         | 2/21 [00:09<01:30,  4.78s/it]\u001b[A\n",
      " 14%|█▍        | 3/21 [00:14<01:25,  4.75s/it]\u001b[A\n",
      " 19%|█▉        | 4/21 [00:19<01:20,  4.74s/it]\u001b[A\n",
      " 24%|██▍       | 5/21 [00:23<01:15,  4.74s/it]\u001b[A\n",
      " 29%|██▊       | 6/21 [00:28<01:13,  4.87s/it]\u001b[A\n",
      " 33%|███▎      | 7/21 [00:33<01:07,  4.82s/it]\u001b[A\n",
      " 38%|███▊      | 8/21 [00:38<01:02,  4.80s/it]\u001b[A\n",
      " 43%|████▎     | 9/21 [00:43<00:57,  4.78s/it]\u001b[A\n",
      " 48%|████▊     | 10/21 [00:47<00:52,  4.77s/it]\u001b[A\n",
      " 52%|█████▏    | 11/21 [00:52<00:47,  4.76s/it]\u001b[A\n",
      " 57%|█████▋    | 12/21 [00:57<00:42,  4.77s/it]\u001b[A\n",
      " 62%|██████▏   | 13/21 [01:02<00:39,  4.88s/it]\u001b[A\n",
      " 67%|██████▋   | 14/21 [01:07<00:33,  4.85s/it]\u001b[A\n",
      " 71%|███████▏  | 15/21 [01:11<00:28,  4.81s/it]\u001b[A\n",
      " 76%|███████▌  | 16/21 [01:16<00:23,  4.78s/it]\u001b[A\n",
      " 81%|████████  | 17/21 [01:21<00:19,  4.77s/it]\u001b[A\n",
      " 86%|████████▌ | 18/21 [01:26<00:14,  4.76s/it]\u001b[A\n",
      " 90%|█████████ | 19/21 [01:31<00:09,  4.83s/it]\u001b[A\n",
      " 95%|█████████▌| 20/21 [01:36<00:04,  4.87s/it]\u001b[A\n",
      "100%|██████████| 21/21 [01:36<00:00,  4.59s/it]\n",
      "Inference:  62%|██████▎   | 5/8 [33:48<18:20, 366.82s/it]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▌         | 1/20 [00:42<13:32, 42.74s/it]\u001b[A\n",
      " 10%|█         | 2/20 [01:24<12:38, 42.14s/it]\u001b[A\n",
      " 15%|█▌        | 3/20 [02:06<11:57, 42.23s/it]\u001b[A\n",
      " 20%|██        | 4/20 [02:48<11:10, 41.91s/it]\u001b[A\n",
      " 25%|██▌       | 5/20 [03:52<12:29, 49.97s/it]\u001b[A\n",
      " 30%|███       | 6/20 [04:34<11:03, 47.38s/it]\u001b[A\n",
      " 35%|███▌      | 7/20 [05:16<09:52, 45.58s/it]\u001b[A\n",
      " 40%|████      | 8/20 [05:59<08:55, 44.60s/it]\u001b[A\n",
      " 45%|████▌     | 9/20 [06:40<08:00, 43.67s/it]\u001b[A\n",
      " 50%|█████     | 10/20 [07:22<07:11, 43.11s/it]\u001b[A\n",
      " 55%|█████▌    | 11/20 [08:04<06:24, 42.74s/it]\u001b[A\n",
      " 60%|██████    | 12/20 [08:46<05:39, 42.49s/it]\u001b[A\n",
      " 65%|██████▌   | 13/20 [09:28<04:55, 42.19s/it]\u001b[A\n",
      " 70%|███████   | 14/20 [10:11<04:16, 42.72s/it]\u001b[A\n",
      " 75%|███████▌  | 15/20 [10:53<03:31, 42.31s/it]\u001b[A\n",
      " 80%|████████  | 16/20 [11:34<02:48, 42.10s/it]\u001b[A\n",
      " 85%|████████▌ | 17/20 [12:16<02:05, 41.81s/it]\u001b[A\n",
      " 90%|█████████ | 18/20 [12:57<01:23, 41.83s/it]\u001b[A\n",
      " 95%|█████████▌| 19/20 [13:56<00:46, 46.77s/it]\u001b[A\n",
      "100%|██████████| 20/20 [14:47<00:00, 44.39s/it]\n",
      "Inference:  75%|███████▌  | 6/8 [48:36<18:08, 544.24s/it]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▌         | 1/20 [00:44<14:12, 44.87s/it]\u001b[A\n",
      " 10%|█         | 2/20 [01:28<13:14, 44.15s/it]\u001b[A\n",
      " 15%|█▌        | 3/20 [02:12<12:29, 44.09s/it]\u001b[A\n",
      " 20%|██        | 4/20 [02:56<11:45, 44.10s/it]\u001b[A\n",
      " 25%|██▌       | 5/20 [03:40<11:02, 44.19s/it]\u001b[A\n",
      " 30%|███       | 6/20 [04:24<10:15, 43.98s/it]\u001b[A\n",
      " 35%|███▌      | 7/20 [05:08<09:33, 44.09s/it]\u001b[A\n",
      " 40%|████      | 8/20 [05:52<08:46, 43.88s/it]\u001b[A\n",
      " 45%|████▌     | 9/20 [06:36<08:03, 43.96s/it]\u001b[A\n",
      " 50%|█████     | 10/20 [07:20<07:19, 43.99s/it]\u001b[A\n",
      " 55%|█████▌    | 11/20 [08:04<06:34, 43.85s/it]\u001b[A\n",
      " 60%|██████    | 12/20 [08:47<05:50, 43.87s/it]\u001b[A\n",
      " 65%|██████▌   | 13/20 [10:00<06:07, 52.44s/it]\u001b[A\n",
      " 70%|███████   | 14/20 [10:45<05:02, 50.41s/it]\u001b[A\n",
      " 75%|███████▌  | 15/20 [11:29<04:02, 48.47s/it]\u001b[A\n",
      " 80%|████████  | 16/20 [12:13<03:08, 47.14s/it]\u001b[A\n",
      " 85%|████████▌ | 17/20 [12:57<02:18, 46.08s/it]\u001b[A\n",
      " 90%|█████████ | 18/20 [13:41<01:30, 45.34s/it]\u001b[A\n",
      " 95%|█████████▌| 19/20 [14:25<00:45, 45.07s/it]\u001b[A\n",
      "100%|██████████| 20/20 [15:09<00:00, 45.46s/it]\n",
      "Inference:  88%|████████▊ | 7/8 [1:03:46<11:03, 663.78s/it]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▌         | 1/20 [00:05<01:39,  5.24s/it]\u001b[A\n",
      " 10%|█         | 2/20 [00:10<01:33,  5.18s/it]\u001b[A\n",
      " 15%|█▌        | 3/20 [00:15<01:29,  5.27s/it]\u001b[A\n",
      " 20%|██        | 4/20 [00:21<01:24,  5.31s/it]\u001b[A\n",
      " 25%|██▌       | 5/20 [00:26<01:18,  5.26s/it]\u001b[A\n",
      " 30%|███       | 6/20 [00:31<01:13,  5.25s/it]\u001b[A\n",
      " 35%|███▌      | 7/20 [00:36<01:07,  5.21s/it]\u001b[A\n",
      " 40%|████      | 8/20 [00:41<01:02,  5.20s/it]\u001b[A\n",
      " 45%|████▌     | 9/20 [00:46<00:56,  5.18s/it]\u001b[A\n",
      " 50%|█████     | 10/20 [00:52<00:52,  5.29s/it]\u001b[A\n",
      " 55%|█████▌    | 11/20 [00:57<00:47,  5.24s/it]\u001b[A\n",
      " 60%|██████    | 12/20 [01:02<00:41,  5.21s/it]\u001b[A\n",
      " 65%|██████▌   | 13/20 [01:07<00:36,  5.19s/it]\u001b[A\n",
      " 70%|███████   | 14/20 [01:13<00:31,  5.19s/it]\u001b[A\n",
      " 75%|███████▌  | 15/20 [01:18<00:25,  5.18s/it]\u001b[A\n",
      " 80%|████████  | 16/20 [01:23<00:21,  5.30s/it]\u001b[A\n",
      " 85%|████████▌ | 17/20 [01:28<00:15,  5.25s/it]\u001b[A\n",
      " 90%|█████████ | 18/20 [01:34<00:10,  5.24s/it]\u001b[A\n",
      " 95%|█████████▌| 19/20 [01:39<00:05,  5.20s/it]\u001b[A\n",
      "100%|██████████| 20/20 [01:44<00:00,  5.22s/it]\n",
      "Inference: 100%|██████████| 8/8 [1:05:31<00:00, 491.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "   ***  Wrote inference_layout_xla_random.csv \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "_INFERENCE_CONFIGS_BATCH_SIZE = 50\n",
    "\n",
    "output_csv_filename = f'inference_layout_{SOURCE}_{SEARCH}.csv'\n",
    "print('\\n\\n   Running inference on test set ...\\n\\n')\n",
    "test_rankings = []\n",
    "\n",
    "assert layout_npz_dataset.test.graph_id is not None\n",
    "for graph in tqdm.tqdm(layout_npz_dataset.test.iter_graph_tensors(),\n",
    "                       total=layout_npz_dataset.test.graph_id.shape[-1],\n",
    "                       desc='Inference'):\n",
    "    num_configs = graph.node_sets['g']['runtimes'].shape[-1]\n",
    "    all_scores = []\n",
    "    for i in tqdm.tqdm(range(0, num_configs, _INFERENCE_CONFIGS_BATCH_SIZE)):\n",
    "        end_i = min(i + _INFERENCE_CONFIGS_BATCH_SIZE, num_configs)\n",
    "        # Take a cut of the configs.\n",
    "        node_set_g = graph.node_sets['g']\n",
    "        subconfigs_graph = tfgnn.GraphTensor.from_pieces(\n",
    "            edge_sets=graph.edge_sets,\n",
    "            node_sets={\n",
    "                'op': graph.node_sets['op'],\n",
    "                'nconfig': tfgnn.NodeSet.from_fields(\n",
    "                    sizes=graph.node_sets['nconfig'].sizes,\n",
    "                    features={\n",
    "                        'feats': graph.node_sets['nconfig']['feats'][:, i:end_i],\n",
    "                    }),\n",
    "                'g': tfgnn.NodeSet.from_fields(\n",
    "                    sizes=tf.constant([1]),\n",
    "                    features={\n",
    "                        'graph_id': node_set_g['graph_id'],\n",
    "                        'runtimes': node_set_g['runtimes'][:, i:end_i],\n",
    "                        'kept_node_ratio': node_set_g['kept_node_ratio'],\n",
    "                    })\n",
    "            })\n",
    "        h = model.forward(subconfigs_graph, num_configs=(end_i - i),\n",
    "                          backprop=False)\n",
    "        all_scores.append(h[0])\n",
    "    all_scores = tf.concat(all_scores, axis=0)\n",
    "    graph_id = graph.node_sets['g']['graph_id'][0].numpy().decode()\n",
    "    sorted_indices = tf.strings.join(\n",
    "        tf.strings.as_string(tf.argsort(all_scores)), ';').numpy().decode()\n",
    "    test_rankings.append((graph_id, sorted_indices))\n",
    "\n",
    "with tf.io.gfile.GFile(output_csv_filename, 'w') as fout:\n",
    "    fout.write('ID,TopConfigs\\n')\n",
    "    for graph_id, ranks in test_rankings:\n",
    "        fout.write(f'layout:{SOURCE}:{SEARCH}:{graph_id},{ranks}\\n')\n",
    "print('\\n\\n   ***  Wrote', output_csv_filename, '\\n\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e70c77",
   "metadata": {
    "papermill": {
     "duration": 0.054143,
     "end_time": "2025-03-26T16:11:54.773290",
     "exception": false,
     "start_time": "2025-03-26T16:11:54.719147",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Combine submission CSVs from all layout collections into one CSV file\n",
    "\n",
    "Finally, after running on all collections, you need to combine the CSV files together (e.g., by concatenation), to prepare the final submission. Specifically, you can modify the constants:\n",
    "\n",
    "```\n",
    "SOURCE = 'xla'  # Can be \"xla\" or \"nlp\"\n",
    "SEARCH = 'random'  # Can be \"random\" or \"default\"\n",
    "```\n",
    "\n",
    "(from a few cells ago) and run for all 4 combinations: SOURCE=(\"xla\", \"nlp\") x SEARCH=(\"random\", \"default\"), then combine all inferences into one file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14c6ec01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T16:11:55.071974Z",
     "iopub.status.busy": "2025-03-26T16:11:55.070694Z",
     "iopub.status.idle": "2025-03-26T16:11:56.524622Z",
     "shell.execute_reply": "2025-03-26T16:11:56.523459Z"
    },
    "papermill": {
     "duration": 1.604456,
     "end_time": "2025-03-26T16:11:56.527191",
     "exception": false,
     "start_time": "2025-03-26T16:11:54.922735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: inference_layout_xla_default.csv: No such file or directory\r\n",
      "cat: inference_layout_nlp_random.csv: No such file or directory\r\n",
      "cat: inference_layout_nlp_default.csv: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!cat inference_layout_xla_random.csv inference_layout_xla_default.csv inference_layout_nlp_random.csv inference_layout_nlp_default.csv > inference_layout_all.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b2027e",
   "metadata": {
    "papermill": {
     "duration": 0.044698,
     "end_time": "2025-03-26T16:11:56.617868",
     "exception": false,
     "start_time": "2025-03-26T16:11:56.573170",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "producing file `\"inference_layout_all.csv\"` that combines all predictions for all layout subcollections. Finally, this file should be combined with the CSV for the tiles collection, as explained next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb38753",
   "metadata": {
    "papermill": {
     "duration": 0.04496,
     "end_time": "2025-03-26T16:11:56.708372",
     "exception": false,
     "start_time": "2025-03-26T16:11:56.663412",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tile Training Pipeline\n",
    "\n",
    "This section will be written by end of September. We prioritized getting this notebook out, as soon as possible, as the above Layout section is (1) more tricky and (2) most of the score depends on it."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 6641124,
     "sourceId": 58266,
     "sourceType": "competition"
    },
    {
     "sourceId": 144043388,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 144045966,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 144045983,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30558,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4444.681662,
   "end_time": "2025-03-26T16:12:00.118743",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-26T14:57:55.437081",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
